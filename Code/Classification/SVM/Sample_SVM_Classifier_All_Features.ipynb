{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c61151bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import joblib\n",
    "import time\n",
    "import xlsxwriter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a471ceaf",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "423cda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training Data\n",
    "def combine_directory_parquets(directory_path):\n",
    "    '''\n",
    "    Combines all parquet files in a directory into a single dataframe.\n",
    "    '''\n",
    "    if directory_path[-1] != '/':\n",
    "        directory_path += '/'\n",
    "    file_list = [f for f in os.listdir(directory_path) if f.endswith('.parquet')]\n",
    "    combined_df = pd.concat([pd.read_parquet(directory_path + f) for f in file_list])\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6684ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  (6003, 4893)\n"
     ]
    }
   ],
   "source": [
    "PATH = '../../../Data/Features/All Features/train'\n",
    "training_data = combine_directory_parquets(PATH)\n",
    "print('Training data: ', training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cccf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Class', 'harmonized_filename', 'image_path_blur', 'image_path_no_blur',\n",
       "       'ViT_Embedding_Element_0', 'ViT_Embedding_Element_1',\n",
       "       'ViT_Embedding_Element_2', 'ViT_Embedding_Element_3',\n",
       "       'ViT_Embedding_Element_4', 'ViT_Embedding_Element_5',\n",
       "       ...\n",
       "       'VGG_Embedding_Element_502', 'VGG_Embedding_Element_503',\n",
       "       'VGG_Embedding_Element_504', 'VGG_Embedding_Element_505',\n",
       "       'VGG_Embedding_Element_506', 'VGG_Embedding_Element_507',\n",
       "       'VGG_Embedding_Element_508', 'VGG_Embedding_Element_509',\n",
       "       'VGG_Embedding_Element_510', 'VGG_Embedding_Element_511'],\n",
       "      dtype='object', length=4893)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8730d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = training_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ce0546",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = training_data.drop(columns = ['Class', 'harmonized_filename', 'image_path_blur', 'image_path_no_blur'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762955cc",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0e7c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_matrices(data):\n",
    "    '''\n",
    "    Takes in a dataframe and returns X and y matrices.\n",
    "    '''\n",
    "    # Create matrices for training\n",
    "    # X is all numeric columns, y is 'Class'\n",
    "    num_cols = data.select_dtypes(include=np.number).columns\n",
    "    X = data[num_cols]\n",
    "    y = data['Class']\n",
    "\n",
    "    # Preprocess with standard scalar\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "    ##################################################################################################\n",
    "\n",
    "def fit_svm_classifier(X_train, y_train, classifier_name):\n",
    "    '''\n",
    "    Fits an SVM classifier to the training data matrices.\n",
    "    '''\n",
    "    output_dir = '../../../Output/Classifier Fitting/SVM/'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    hyperparameter_grid = {\n",
    "    'c_values' :  np.logspace(-1, 2, num = 3),\n",
    "    'kernel_grid' :  ['poly'],\n",
    "    'degree_grid' : [2, 3, 5],\n",
    "    'k_folds' : 5\n",
    "    }\n",
    "    \n",
    "    # Setup the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'C': hyperparameter_grid['c_values'],\n",
    "        'kernel': hyperparameter_grid['kernel_grid'],\n",
    "        'degree': hyperparameter_grid['degree_grid']\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Initialize the SVM classifier\n",
    "    svm = SVC()\n",
    "    \n",
    "    # Setup GridSearchCV\n",
    "    gs = GridSearchCV(svm, param_grid, cv = hyperparameter_grid['k_folds'], scoring = 'accuracy', return_train_score = True)\n",
    "    \n",
    "    # Fit the model\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Training time\n",
    "    fit_time = time.time() - start_time\n",
    "    \n",
    "    # Best model\n",
    "    best_model = gs.best_estimator_\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump(best_model, output_dir + classifier_name + ' Best Model.joblib')\n",
    "\n",
    "    runtime_minutes = fit_time / 60\n",
    "    print(\"Training time in minutes: \", runtime_minutes)\n",
    "    runtime_per_image = runtime_minutes / len(y_train)\n",
    "    print(\"Training time per image in minutes: \", runtime_per_image)\n",
    "    train_accuracy_best_model = gs.best_estimator_.score(X_train, y_train)\n",
    "    print(\"Train accuracy of best model: \", train_accuracy_best_model)\n",
    "    mean_cross_validated_accuracy = gs.best_score_\n",
    "    print(\"Mean cross validated accuracy of best model: \", mean_cross_validated_accuracy)\n",
    "\n",
    "    training_statistics_df = pd.DataFrame({\n",
    "        'runtime_minutes': [runtime_minutes],\n",
    "        'runtime_per_image': [runtime_per_image],\n",
    "        'train_accuracy_best_model': [train_accuracy_best_model],\n",
    "        'mean_cross_validated_accuracy': [mean_cross_validated_accuracy]\n",
    "    })\n",
    "\n",
    "    training_statistics_df.to_excel(output_dir + classifier_name + ' Training Statistics.xlsx')\n",
    "\n",
    "    print(\"Hyperparameters searched: \", hyperparameter_grid)\n",
    "    print(\"Tuned hyperparameters: \", gs.best_params_)\n",
    "\n",
    "    joblib.dump(hyperparameter_grid, output_dir + classifier_name + ' Hyperparameter Settings.joblib')\n",
    "    joblib.dump(gs.best_params_, output_dir + classifier_name + ' Tuned Hyperparameters.joblib')\n",
    "    \n",
    "    ##################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b06f33",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c82befa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time in minutes:  0.5085772355397542\n",
      "Training time per image in minutes:  0.0010171544710795084\n",
      "Train accuracy of best model:  1.0\n",
      "Mean cross validated accuracy of best model:  0.65\n",
      "Hyperparameters searched:  {'c_values': array([  0.1       ,   3.16227766, 100.        ]), 'kernel_grid': ['poly'], 'degree_grid': [2, 3, 5], 'k_folds': 5}\n",
      "Tuned hyperparameters:  {'C': 100.0, 'degree': 2, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "# Training:\n",
    "training_data = combine_directory_parquets(PATH)\n",
    "X_train, y_train = prepare_matrices(training_data)\n",
    "X_train = X_train[:500]\n",
    "y_train = y_train[:500]\n",
    "fit_svm_classifier(X_train, y_train, 'SVM_Classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3666e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(test_data, X_test, classifier_name):\n",
    "    '''\n",
    "    Makes predictions on the test data using the best SVM model.\n",
    "    '''\n",
    "    output_dir = '../../../Output/Classifier Fitting/SVM/'\n",
    "    inference_dir = '../../../Output/Classifier Inference/SVM/'\n",
    "    predictions_dir = '../../../Data/Predictions/SVM/'\n",
    "\n",
    "    if not os.path.exists(inference_dir):\n",
    "        os.makedirs(inference_dir)\n",
    "    if not os.path.exists(predictions_dir):\n",
    "        os.makedirs(predictions_dir)\n",
    "\n",
    "    best_model = joblib.load(output_dir + classifier_name + ' Best Model.joblib')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    predictions = best_model.predict(X_test)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    runtime_minutes = (end_time - start_time) / 60\n",
    "    print(\"Prediction time in minutes: \", runtime_minutes)\n",
    "    runtime_per_image = runtime_minutes / len(test_data)\n",
    "    print(\"Prediction time per image in minutes: \", runtime_per_image)\n",
    "\n",
    "    prediction_statistics_df = pd.DataFrame({\n",
    "        'runtime_minutes': [runtime_minutes],\n",
    "        'runtime_per_image': [runtime_per_image]\n",
    "    })\n",
    "\n",
    "    prediction_statistics_df.to_excel(inference_dir + classifier_name + ' Prediction Statistics.xlsx', index=False)\n",
    "\n",
    "    test_data['SVM_Classification'] = predictions\n",
    "\n",
    "    limited_test_data = test_data[[col for col in test_data.columns if col not in test_data.select_dtypes(include = np.number).columns]]\n",
    "\n",
    "    limited_test_data.to_excel(predictions_dir + 'SVM_Classifier_Predictions_' + classifier_name + '.xlsx', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae714407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time in minutes:  0.005554600556691488\n",
      "Prediction time per image in minutes:  1.1109201113382976e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2178e674f048>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['SVM_Classification'] = predictions\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "PATH_test = '../../../Data/Features/All Features/test'\n",
    "test_data = combine_directory_parquets(PATH_test)\n",
    "X_test, y_test = prepare_matrices(test_data)\n",
    "X_test = X_test[:500]\n",
    "y_test = y_test[:500]\n",
    "make_predictions(test_data[:500], X_test, 'SVM_Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6481a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
